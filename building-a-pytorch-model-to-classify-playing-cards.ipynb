{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cec252a7",
   "metadata": {
    "papermill": {
     "duration": 0.002603,
     "end_time": "2025-02-11T22:15:01.875040",
     "exception": false,
     "start_time": "2025-02-11T22:15:01.872437",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **Building a PyTorch Model to Classify Playing Cards**\n",
    "\n",
    "## **Introduction**\n",
    "\n",
    "In recent years, deep learning has revolutionized the field of computer vision, enabling machines to perform complex image recognition tasks with remarkable accuracy. One of the most popular frameworks for deep learning is **PyTorch**, known for its flexibility, simplicity, and dynamic computation capabilities. This project aims to introduce the fundamentals of PyTorch by building an image classification model that can identify playing cards from a high-quality dataset.\n",
    "\n",
    "Playing card recognition serves as an excellent entry point for learning deep learning concepts, given the structured nature of the dataset and the clear visual distinctions between different classes. Through this project, we will cover key deep learning workflows, from dataset preparation to model training and evaluation, while mastering PyTorch’s essential components like datasets, data loaders, models, and training loops.\n",
    "\n",
    "By the end of this project, you'll not only have a robust playing card classifier but also a solid understanding of how to build and train deep learning models using PyTorch.\n",
    "\n",
    "\n",
    "## **Dataset Description**\n",
    "\n",
    "The dataset used in this project is a **high-quality collection of playing card images** designed specifically for image classification tasks. Here’s an overview of the dataset's key features:\n",
    "\n",
    "- **Image Format & Quality:**  \n",
    "  All images are in **JPG format** with dimensions **224 x 224 x 3** (RGB channels). The images are cropped to ensure that each card occupies **over 50%** of the frame, providing clear and consistent visuals for the model to learn from.\n",
    "\n",
    "- **Dataset Size:**\n",
    "  - **Training Set:** 7,624 images.\n",
    "  - **Validation Set:** 265 images.\n",
    "  - **Test Set:** 265 images.\n",
    "\n",
    "- **Class Distribution:**  \n",
    "  The dataset is organized into **53 subdirectories** within each partition (train, validation, test), representing each type of playing card (e.g., \"ace of clubs,\" \"king of hearts,\" \"joker\").\n",
    "\n",
    "- **CSV File:**  \n",
    "  The dataset includes a CSV file that maps image file paths to their corresponding labels, allowing for easy dataset loading and manipulation.\n",
    "\n",
    "### **Sample Directory Structure**\n",
    "\n",
    "```\n",
    "/dataset\n",
    "    /train\n",
    "        /ace of clubs\n",
    "        /ace of diamonds\n",
    "        ...\n",
    "        /joker\n",
    "    /valid\n",
    "        /ace of clubs\n",
    "        /ace of diamonds\n",
    "        ...\n",
    "        /joker\n",
    "    /test\n",
    "        /ace of clubs\n",
    "        /ace of diamonds\n",
    "        ...\n",
    "        /joker\n",
    "    labels.csv\n",
    "```\n",
    "\n",
    "\n",
    "## **Project Objectives**\n",
    "\n",
    "In this project, we aim to build a **playing card classification model** using PyTorch, covering the full model development pipeline. The key objectives include:\n",
    "\n",
    "1. **Understanding PyTorch Datasets and Data Loaders:**  \n",
    "   - Learn how to structure and load image data efficiently using custom dataset classes and data loaders.\n",
    "   - Apply data transformations to standardize image input for the model.\n",
    "\n",
    "2. **Building the PyTorch Model:**  \n",
    "   - Utilize a pre-trained **EfficientNet** architecture for transfer learning, modifying the final layers to suit our 53-class classification problem.\n",
    "   - Understand model architecture and layer connections in PyTorch.\n",
    "\n",
    "3. **Training the Model:**  \n",
    "   - Write a custom **training loop** to handle model training and validation.\n",
    "   - Use common deep learning techniques like **backpropagation**, **loss calculation**, and **optimizer tuning**.\n",
    "\n",
    "4. **Evaluating Model Performance:**  \n",
    "   - Visualize training and validation performance using loss and accuracy plots.\n",
    "   - Test the model on unseen data and visualize predictions to evaluate accuracy.\n",
    "\n",
    "5. **Deploying and Improving the Model:**  \n",
    "   - Suggest improvements like data augmentation, hyperparameter tuning, and experimenting with different architectures.\n",
    "\n",
    "---\n",
    "\n",
    "## **What We’ll Do in This Project**\n",
    "\n",
    "Here’s a step-by-step overview of our project workflow:\n",
    "\n",
    "1. **Setup and Preparation:**\n",
    "   - Install and import the necessary libraries, including PyTorch, TorchVision, and timm (for model architectures).\n",
    "   - Configure the environment to utilize **GPU acceleration** for faster training.\n",
    "\n",
    "2. **Data Loading and Preprocessing:**\n",
    "   - Load the dataset using PyTorch’s `Dataset` and `DataLoader` classes.\n",
    "   - Apply **image transformations** (resize, normalization) to ensure consistent input dimensions for the model.\n",
    "\n",
    "3. **Model Building:**\n",
    "   - Leverage the **EfficientNet-B0** pre-trained model from the `timm` library.\n",
    "   - Modify the final classification layer to output predictions for 53 card classes.\n",
    "\n",
    "4. **Model Training:**\n",
    "   - Define a **loss function** (`CrossEntropyLoss`) and an **optimizer** (`Adam`).\n",
    "   - Write a training loop that handles **forward propagation**, **loss calculation**, **backpropagation**, and **weight updates**.\n",
    "   - Include validation during training to monitor for **overfitting** or **underfitting**.\n",
    "\n",
    "5. **Evaluation and Visualization:**\n",
    "   - Plot **loss** and **accuracy** curves to visualize training performance.\n",
    "   - Test the model on new images and display the predictions using **visualizations**.\n",
    "\n",
    "6. **Final Evaluation and Accuracy Calculation:**\n",
    "   - Calculate the final accuracy on the **test set** and explore model performance on individual images.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b9f816",
   "metadata": {
    "papermill": {
     "duration": 0.001533,
     "end_time": "2025-02-11T22:15:01.878587",
     "exception": false,
     "start_time": "2025-02-11T22:15:01.877054",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### **Playing Card Classification Using PyTorch: A Step-by-Step Guide**\n",
    "\n",
    "In this project, we'll build a playing card classifier using **PyTorch**. Each step will include explanations of important PyTorch concepts to help you understand how deep learning models are built, trained, and evaluated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b48f80",
   "metadata": {
    "papermill": {
     "duration": 0.001475,
     "end_time": "2025-02-11T22:15:01.881682",
     "exception": false,
     "start_time": "2025-02-11T22:15:01.880207",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## **1. Setup and Library Imports**\n",
    "\n",
    "**What are we doing here?**  \n",
    "We're importing the necessary libraries to build and train our model. PyTorch (`torch`) is our deep learning framework, and we'll use `torchvision` for image transformations and dataset handling. We also import `timm` to use pre-trained models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72cd3635",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-11T22:15:01.886231Z",
     "iopub.status.busy": "2025-02-11T22:15:01.885914Z",
     "iopub.status.idle": "2025-02-11T22:15:15.083182Z",
     "shell.execute_reply": "2025-02-11T22:15:15.082271Z"
    },
    "papermill": {
     "duration": 13.20156,
     "end_time": "2025-02-11T22:15:15.084829",
     "exception": false,
     "start_time": "2025-02-11T22:15:01.883269",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Importing Required Libraries\n",
    "import torch  # Main PyTorch library\n",
    "import torch.nn as nn  # For building neural network layers\n",
    "import torch.optim as optim  # For optimization algorithms like Adam\n",
    "from torch.utils.data import Dataset, DataLoader  # For dataset handling and batching\n",
    "import torchvision.transforms as transforms  # For image preprocessing\n",
    "from torchvision.datasets import ImageFolder  # To load images from folders\n",
    "import timm  # For using pre-trained models like EfficientNet\n",
    "\n",
    "import matplotlib.pyplot as plt  # For visualizations\n",
    "import numpy as np  # For numerical operations\n",
    "from tqdm.notebook import tqdm  # For progress bars\n",
    "from PIL import Image  # For image loading and handling\n",
    "from glob import glob  # For finding file paths\n",
    "import sys  # To check system information\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "838c1c94",
   "metadata": {
    "papermill": {
     "duration": 0.001565,
     "end_time": "2025-02-11T22:15:15.088622",
     "exception": false,
     "start_time": "2025-02-11T22:15:15.087057",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## **2. Dataset Class and Data Loading**\n",
    "**Why is this important?**  \n",
    "In PyTorch, data loading is handled through **custom datasets** and **data loaders**. This structure helps efficiently load and preprocess data in batches, which is crucial for training on large datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ec32b8f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-11T22:15:15.093772Z",
     "iopub.status.busy": "2025-02-11T22:15:15.093410Z",
     "iopub.status.idle": "2025-02-11T22:15:23.570953Z",
     "shell.execute_reply": "2025-02-11T22:15:23.569338Z"
    },
    "papermill": {
     "duration": 8.482431,
     "end_time": "2025-02-11T22:15:23.572926",
     "exception": false,
     "start_time": "2025-02-11T22:15:15.090495",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape: torch.Size([3, 224, 224]), Label: 0 (ace of clubs)\n"
     ]
    }
   ],
   "source": [
    "# Dataset Class with Transformations\n",
    "class PlayingCardDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Custom dataset class for loading playing card images.\n",
    "    It uses ImageFolder to automatically label images based on folder names.\n",
    "    \"\"\"\n",
    "    def __init__(self, data_dir, transform=None):\n",
    "        self.data = ImageFolder(data_dir, transform=transform)  # Automatically labels images from folder names\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)  # Returns the number of samples in the dataset\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]  # Returns an image and its label at a given index\n",
    "    \n",
    "    @property\n",
    "    def classes(self):\n",
    "        return self.data.classes  # Returns the class names (card names)\n",
    "\n",
    "# Transformations for Preprocessing Images\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize images to 224x224 (same as EfficientNet's expected input)\n",
    "    transforms.ToTensor(),  # Convert images to PyTorch tensors\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  # Normalize pixel values to [-1, 1] range\n",
    "])\n",
    "\n",
    "# Dataset Paths\n",
    "train_folder = '/kaggle/input/cards-image-datasetclassification/train'\n",
    "valid_folder = '/kaggle/input/cards-image-datasetclassification/valid'\n",
    "test_folder = '/kaggle/input/cards-image-datasetclassification/test'\n",
    "\n",
    "# Loading Datasets with Transformations Applied\n",
    "train_dataset = PlayingCardDataset(train_folder, transform=transform)\n",
    "val_dataset = PlayingCardDataset(valid_folder, transform=transform)\n",
    "test_dataset = PlayingCardDataset(test_folder, transform=transform)\n",
    "\n",
    "# DataLoaders for Batching (Speeds up training by loading data in chunks)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)  # Shuffle during training for better generalization\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Displaying Sample Data\n",
    "image, label = train_dataset[100]\n",
    "print(f'Image shape: {image.shape}, Label: {label} ({train_dataset.classes[label]})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b72278",
   "metadata": {
    "papermill": {
     "duration": 0.001741,
     "end_time": "2025-02-11T22:15:23.576968",
     "exception": false,
     "start_time": "2025-02-11T22:15:23.575227",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ec2f97",
   "metadata": {
    "papermill": {
     "duration": 0.001554,
     "end_time": "2025-02-11T22:15:23.580460",
     "exception": false,
     "start_time": "2025-02-11T22:15:23.578906",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1e0f65a9",
   "metadata": {
    "papermill": {
     "duration": 0.002257,
     "end_time": "2025-02-11T22:15:23.584824",
     "exception": false,
     "start_time": "2025-02-11T22:15:23.582567",
     "status": "completed"
    },
    "tags": []
   },
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 2579480,
     "sourceId": 4532039,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30886,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 26.467358,
   "end_time": "2025-02-11T22:15:26.120101",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-02-11T22:14:59.652743",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
